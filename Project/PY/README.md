Данные для обучения расположены в архиве, которые можно скачать по ссылке: https://bit.ly/2T8LiLJ

Распаковать данные в директорию ./data/

Запустить DataCheck, чтобы исключить данные с неправильным форматом.

Отфильтрованные данные будут находиться в директории ./correct_data/

Запустить MIDItoNPy, чтобы перевести данные в numpy array и сохранить в файле ./npy_data/NPYData.npy (готовые данные: http://bit.do/eMAxV)

Запустить Main для обучения и генерации модели в pt файл.

Запустить Generation для генерации. Передать на вход название файла без расширения и сид. Будкт созданы два файла название.mid и название.wav

Для генерации нужно использовать pt модель. Чтобы изменить используемую модель, нужно указать в коде программы путь к ней (rnn.load_state_dict(torch.load("ПУТЬ"))) Список некоторых сгенированных моделей:

https://drive.google.com/open?id=1jgC_ifMaewz9O62XYb1Pm5I_ZPCCFVLU - Сеть обучалась на всех данных 523 минуты, выход зачастую хаотичный и имеет слабый каркас, так как в дата сете ~2400 разных композиций.

https://drive.google.com/open?id=1m9WLxwEJkk8ysCYflYYhgOfFrFRjawre - Сеть обучалась ~2 часа на композициях С.В. Рахманинова. Выходные композиции часто похожи друг на друга, но действительно звучат, как те, на которых сеть обучалась.

https://drive.google.com/open?id=1l27dXv3Ac5YhOMrI-9iSJU-HdL4WQItu - Сеть обучалась ~6 часов на композициях Фридерика Шопена. Генерируемые композиции, очевидно, уступают в структуре произведениям Шопена, но кусками действительно похожи на его стиль.
